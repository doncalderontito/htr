{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/dataiku/deng/DSS_DATA/code-envs/python/python36deng/lib/python3.6/site-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['copy']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataiku\n",
    "from dataiku import pandasutils as pdu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: load a DSS dataset as a Pandas dataframe\n",
    "modelFolder = dataiku.Folder(\"model\")\n",
    "mappingFolder = dataiku.Folder(\"mapping\")\n",
    "imgFolder  = dataiku.Folder(\"scanned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelPath= modelFolder.get_path()+\"/\"\n",
    "mappingPath=mappingFolder.get_path()+\"/\"\n",
    "imgPath=imgFolder.get_path()+\"/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/cs/dataiku/deng/DSS_DATA/managed_datasets/CHATBOT_OCR/9SHpTVZA/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/cs/dataiku/deng/DSS_DATA/managed_datasets/CHATBOT_OCR/MK98HL3A/'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(imgPath)\n",
    "mappingPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import keras\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "border_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Roi:\n",
    "    def __init__(self, roi, x, y, w, h):\n",
    "        self.roi = roi\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.w = w\n",
    "        self.h = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_image(image):\n",
    "    th = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 125, 20)\n",
    "    blurred = cv2.medianBlur(th, 7)\n",
    "    inverted = cv2.bitwise_not(blurred)\n",
    "    eroded = cv2.erode(inverted, np.ones((1, 1), np.uint8))\n",
    "    dilated = cv2.dilate(eroded, np.ones((2, 2), np.uint8))\n",
    "    # cv2.imwrite('denoised.jpg', dilated)\n",
    "    plt.imshow(dilated, 'gray')\n",
    "    return dilated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(model_name):\n",
    "    return keras.models.load_model(modelPath + model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_labels(file_name):\n",
    "    #with open('mappings/' + file_name, 'r') as mapping:\n",
    "    with open(mappingPath + file_name, 'r') as mapping:\n",
    "        lines = mapping.readlines()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        lines[i] = lines[i].replace('\\n', '')\n",
    "\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_model_and_mapping():\n",
    "    return {\n",
    "        1: (load_model('capital_only_model_99_39'), get_labels('capital_letters.txt')),\n",
    "        2: (load_model('digit_only_model_99_43'), get_labels('digits.txt')),\n",
    "        3: (load_model('letters_and_digits_bymerge_90_35'), get_labels('all_characters.txt'))\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_border(img):\n",
    "    h, w = img.shape\n",
    "    pad_h, pad_w = 0, 0\n",
    "    if w > h:\n",
    "        pad_h = int((w - h) / 2)\n",
    "    else:\n",
    "        pad_w = int((h - w) / 2)\n",
    "    padded_img = cv2.copyMakeBorder(img, top=pad_h, bottom=pad_h, left=pad_w, right=pad_w,\n",
    "                                    borderType=cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "    return padded_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_character(classifier, labels, image, text, position, choice):\n",
    "    image = cv2.dilate(image, kernel=np.ones((2, 2), np.uint8), iterations=1)\n",
    "    text_1 = list()\n",
    "    X_list = list()\n",
    "    pred_list = list()\n",
    "    # cv2.imshow('Predicting Image', image)\n",
    "    # cv2.waitKey(0)\n",
    "    X = image.reshape(1, 784)\n",
    "    X = X / 255\n",
    "    X = X.reshape(X.shape[0], int(X.shape[1] ** 0.5), int(X.shape[1] ** 0.5))\n",
    "    X = X[..., np.newaxis]\n",
    "    pred_list.append(X)\n",
    "    pred = classifier.predict(X)\n",
    "    print(pred.shape)\n",
    "    largest = pred.argmax()\n",
    "    nbr = labels[largest]\n",
    "    nbr_1 = labels[np.delete(pred, largest).argmax()]\n",
    "    nbr = nbr.split(' ')\n",
    "    nbr_1 = nbr_1.split(' ')\n",
    "    if (choice == 3 and position > 0 and chr(int(nbr[1])).isupper()):\n",
    "        text.append(chr(int(nbr[1]) + 32))\n",
    "    else:\n",
    "        text.append(chr(int(nbr[1])))\n",
    "    text_1.append(chr(int(nbr_1[1])))\n",
    "    for i, p in enumerate(pred.reshape(-1, 1)):\n",
    "        print(\"Predicted: %c with %f\" % (chr(int(labels[i].split(' ')[1])), p))\n",
    "    X_list.append(X)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def segment(image, kernel, isPara):\n",
    "    orig_image = copy.copy(image)\n",
    "    # dilation\n",
    "    img_dilation = cv2.dilate(image, kernel=kernel, iterations=1)\n",
    "    plt.imshow(cv2.resize(img_dilation, (500, 200)), 'gray')\n",
    "    # find contours\n",
    "    ctrs, hier = cv2.findContours(img_dilation.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # sort contours\n",
    "    if isPara:\n",
    "        sorted_ctrs = sorted(ctrs, key=lambda ctr: (cv2.boundingRect(ctr)[1], cv2.boundingRect(ctr)[0]))\n",
    "    else:\n",
    "        sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
    "\n",
    "    roi_list = list()\n",
    "\n",
    "    roi_objects = []\n",
    "\n",
    "    for i, ctr in enumerate(sorted_ctrs):\n",
    "        # Get bounding box\n",
    "        x, y, w, h = cv2.boundingRect(ctr)\n",
    "\n",
    "        # Getting ROI\n",
    "        roi = orig_image[y:y + h, x:x + w]\n",
    "        # show ROI\n",
    "        roi_list.append(roi)\n",
    "        roi_objects.append(Roi(roi, x, y, w, h))\n",
    "        # cv2.imshow('segment no:'+str(i), roi)\n",
    "        # cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        # cv2.waitKey(0)\n",
    "\n",
    "    # cv2.imshow('marked areas', image)\n",
    "    # cv2.waitKey(0)\n",
    "    # print('Recognized' + text)\n",
    "    return roi_list, roi_objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def image_resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and\n",
    "    # grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the\n",
    "    # original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the\n",
    "        # dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the\n",
    "        # dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation=inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def recognize_image(imagepath, choice=1):\n",
    "    (classifier, labels) = get_model_and_mapping()[choice]\n",
    "\n",
    "    image = cv2.imread(imagepath, 0)\n",
    "\n",
    "    image = image_resize(image, None, 1110)\n",
    "\n",
    "    blurred = process_image(image)\n",
    "\n",
    "    segmented_lines, lines_objects = segment(blurred, np.ones((10, 500), np.uint8), True)\n",
    "\n",
    "    text = list()\n",
    "\n",
    "    for line in range(len(lines_objects)):\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        _, words_obj = segment(lines_objects[line].roi, np.ones((5, 7), np.uint8), False)\n",
    "\n",
    "        for i in range(len(words_obj)-1):\n",
    "            distances.append(words_obj[i+1].x-(words_obj[i].x+words_obj[i].w))\n",
    "\n",
    "        minimum = maximum = 0\n",
    "\n",
    "        try:\n",
    "            minimum = np.min(distances)\n",
    "            maximum = np.max(distances)\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "        for i in range(len(words_obj)):\n",
    "            padded_img = add_border(words_obj[i].roi)\n",
    "            padded_img = cv2.resize(padded_img, (28 - (border_size * 2), 28 - (border_size * 2)),\n",
    "                                    interpolation=cv2.INTER_AREA)\n",
    "            padded_img = cv2.copyMakeBorder(padded_img, border_size, border_size, border_size, border_size,\n",
    "                                            cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "            padded_img[padded_img>50] = 255;\n",
    "            text = predict_character(classifier, labels, padded_img, text, i, choice)\n",
    "            print(text)\n",
    "            \n",
    "            print(distances)\n",
    "\n",
    "            if minimum >= maximum/2:\n",
    "                continue\n",
    "\n",
    "            if i < len(words_obj)-1 and distances[i] > maximum/2:\n",
    "                text.append(' ')\n",
    "        \n",
    "        if line <  len(lines_objects)-1:\n",
    "            text.append('\\n')\n",
    "\n",
    "    print(''.join(text))\n",
    "    \n",
    "    return ''.join(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 26)\n",
      "Predicted: A with 0.000000\n",
      "Predicted: B with 0.000000\n",
      "Predicted: C with 0.000000\n",
      "Predicted: D with 0.000000\n",
      "Predicted: E with 0.000000\n",
      "Predicted: F with 0.000000\n",
      "Predicted: G with 0.000000\n",
      "Predicted: H with 0.999999\n",
      "Predicted: I with 0.000000\n",
      "Predicted: J with 0.000000\n",
      "Predicted: K with 0.000000\n",
      "Predicted: L with 0.000000\n",
      "Predicted: M with 0.000001\n",
      "Predicted: N with 0.000000\n",
      "Predicted: O with 0.000000\n",
      "Predicted: P with 0.000000\n",
      "Predicted: Q with 0.000000\n",
      "Predicted: R with 0.000000\n",
      "Predicted: S with 0.000000\n",
      "Predicted: T with 0.000000\n",
      "Predicted: U with 0.000000\n",
      "Predicted: V with 0.000000\n",
      "Predicted: W with 0.000000\n",
      "Predicted: X with 0.000000\n",
      "Predicted: Y with 0.000000\n",
      "Predicted: Z with 0.000000\n",
      "['H']\n",
      "[76, 60, 29, 27]\n",
      "(1, 26)\n",
      "Predicted: A with 0.000000\n",
      "Predicted: B with 0.000000\n",
      "Predicted: C with 0.000000\n",
      "Predicted: D with 0.000000\n",
      "Predicted: E with 1.000000\n",
      "Predicted: F with 0.000000\n",
      "Predicted: G with 0.000000\n",
      "Predicted: H with 0.000000\n",
      "Predicted: I with 0.000000\n",
      "Predicted: J with 0.000000\n",
      "Predicted: K with 0.000000\n",
      "Predicted: L with 0.000000\n",
      "Predicted: M with 0.000000\n",
      "Predicted: N with 0.000000\n",
      "Predicted: O with 0.000000\n",
      "Predicted: P with 0.000000\n",
      "Predicted: Q with 0.000000\n",
      "Predicted: R with 0.000000\n",
      "Predicted: S with 0.000000\n",
      "Predicted: T with 0.000000\n",
      "Predicted: U with 0.000000\n",
      "Predicted: V with 0.000000\n",
      "Predicted: W with 0.000000\n",
      "Predicted: X with 0.000000\n",
      "Predicted: Y with 0.000000\n",
      "Predicted: Z with 0.000000\n",
      "['H', ' ', 'E']\n",
      "[76, 60, 29, 27]\n",
      "(1, 26)\n",
      "Predicted: A with 0.000000\n",
      "Predicted: B with 0.000000\n",
      "Predicted: C with 0.000000\n",
      "Predicted: D with 0.000000\n",
      "Predicted: E with 0.000000\n",
      "Predicted: F with 0.000000\n",
      "Predicted: G with 0.000000\n",
      "Predicted: H with 0.000000\n",
      "Predicted: I with 0.000000\n",
      "Predicted: J with 0.000000\n",
      "Predicted: K with 0.000000\n",
      "Predicted: L with 1.000000\n",
      "Predicted: M with 0.000000\n",
      "Predicted: N with 0.000000\n",
      "Predicted: O with 0.000000\n",
      "Predicted: P with 0.000000\n",
      "Predicted: Q with 0.000000\n",
      "Predicted: R with 0.000000\n",
      "Predicted: S with 0.000000\n",
      "Predicted: T with 0.000000\n",
      "Predicted: U with 0.000000\n",
      "Predicted: V with 0.000000\n",
      "Predicted: W with 0.000000\n",
      "Predicted: X with 0.000000\n",
      "Predicted: Y with 0.000000\n",
      "Predicted: Z with 0.000000\n",
      "['H', ' ', 'E', ' ', 'L']\n",
      "[76, 60, 29, 27]\n",
      "(1, 26)\n",
      "Predicted: A with 0.000000\n",
      "Predicted: B with 0.000000\n",
      "Predicted: C with 0.000000\n",
      "Predicted: D with 0.000000\n",
      "Predicted: E with 0.000000\n",
      "Predicted: F with 0.000000\n",
      "Predicted: G with 0.000000\n",
      "Predicted: H with 0.000000\n",
      "Predicted: I with 0.000000\n",
      "Predicted: J with 0.000000\n",
      "Predicted: K with 0.000000\n",
      "Predicted: L with 1.000000\n",
      "Predicted: M with 0.000000\n",
      "Predicted: N with 0.000000\n",
      "Predicted: O with 0.000000\n",
      "Predicted: P with 0.000000\n",
      "Predicted: Q with 0.000000\n",
      "Predicted: R with 0.000000\n",
      "Predicted: S with 0.000000\n",
      "Predicted: T with 0.000000\n",
      "Predicted: U with 0.000000\n",
      "Predicted: V with 0.000000\n",
      "Predicted: W with 0.000000\n",
      "Predicted: X with 0.000000\n",
      "Predicted: Y with 0.000000\n",
      "Predicted: Z with 0.000000\n",
      "['H', ' ', 'E', ' ', 'L', 'L']\n",
      "[76, 60, 29, 27]\n",
      "(1, 26)\n",
      "Predicted: A with 0.000000\n",
      "Predicted: B with 0.000000\n",
      "Predicted: C with 0.000000\n",
      "Predicted: D with 0.000000\n",
      "Predicted: E with 0.000000\n",
      "Predicted: F with 0.000000\n",
      "Predicted: G with 0.000000\n",
      "Predicted: H with 0.000000\n",
      "Predicted: I with 0.000000\n",
      "Predicted: J with 0.000000\n",
      "Predicted: K with 0.000000\n",
      "Predicted: L with 0.000000\n",
      "Predicted: M with 0.000000\n",
      "Predicted: N with 0.000000\n",
      "Predicted: O with 1.000000\n",
      "Predicted: P with 0.000000\n",
      "Predicted: Q with 0.000000\n",
      "Predicted: R with 0.000000\n",
      "Predicted: S with 0.000000\n",
      "Predicted: T with 0.000000\n",
      "Predicted: U with 0.000000\n",
      "Predicted: V with 0.000000\n",
      "Predicted: W with 0.000000\n",
      "Predicted: X with 0.000000\n",
      "Predicted: Y with 0.000000\n",
      "Predicted: Z with 0.000000\n",
      "['H', ' ', 'E', ' ', 'L', 'L', 'O']\n",
      "[76, 60, 29, 27]\n",
      "H E LLO\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "hello = imgPath+\"hello.png\"\n",
    "if __name__ == '__main__':\n",
    "    recognize_image(hello)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "creator": "A580106",
  "customFields": {},
  "kernelspec": {
   "display_name": "Python (env python36deng)",
   "language": "python",
   "name": "py-dku-venv-python36deng"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "tags": []
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
